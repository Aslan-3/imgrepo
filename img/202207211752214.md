Java基础

> Java面向对象有哪些特征？

- ==封装==
  - 封装隐藏了类的内部实现机制，可以在不影响使用的情况下改变类的内部结构，同时也保护了数据。

- ==继承==
  - 继承是从已有的类中派生出新的类，新的类能吸收已有类的数据属性和行为，并拓展新的能力。

- ==多态==
  - 多态指的是类和类的关系，两个类有继承关系，存在方法的重写，故而可以在调用时有父类引用指向子类对象。
  - 多态三个必要条件：``继承``，``重写``，``父类引用指向子类对象``。



### Java集合

### hashmap 的实现原理

在jdk1.7之前HashMap是基于数组和[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)实现的，而且采用头插法。

而jdk1.8 之后在解决哈希冲突时有了较大的变化，当[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)长度大于阈值（默认为 8）（将[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)转换成[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)）时，将[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)转化为[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)，以减少搜索时间。采用尾插法。

HashMap默认的初始化大小为 16。当HashMap中的**元素个数之和**大于负载因子*当前容量的时候就要进行扩充，容量变为原来的 2 倍。（这里注意不是数组中的个数，而且数组中和链/树中的所有元素个数之和！）

> 注意：我们还可以在预知存储数据量的情况下，提前设置初始容量（初始容量 = 预知数据量 / 加载因子）。这样做的好处是可以减少 resize() 操作，提高 HashMap 的效率

HashMap是**线程不安全**的，并发环境下建议使用**ConcurrentHashMap**，其主要体现：

1.在jdk1.7中，在多线程环境下，扩容时会造成**环形链**或数据丢失。

2.在jdk1.8中，在多线程环境下，会发生**数据覆盖**的情况。

#### 追问：HashMap的put方法说一下。

回答：通过阅读源码，可以从jdk1.7和1.8两个方面来回答

1.根据key通过哈希[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)与与运算得出数组下标

2.如果数组下标元素为空，则将key和value封装为Entry对象（JDK1.7是Entry对象，JDK1.8是Node对象）并放入该位置。

3.如果数组下标位置元素不为空，则要分情况

(i)如果是在JDK1.7，则**首先会判断是否需要扩容**，如果要扩容就进行扩容，如果不需要扩容就生成Entry对象，并使用**头插法**添加到当前[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)中。

(ii)如果是在JDK1.8中，则会先判断当前位置上的TreeNode类型，看是[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)还是[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)Node

(a)如果是[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)TreeNode，则将key和value封装为一个[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)节点并添加到[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)中去，在这个过程中会判断[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)中是否存在当前key，如果存在则更新value。

(b)如果此位置上的Node对象是[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)节点，则将key和value封装为一个Node并通过尾插法插入到[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)的最后位置去，因为是尾插法，所以需要遍历[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)，在遍历过程中会判断是否存在当前key，如果存在则更新其value，当遍历完[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)后，将新的Node插入到[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)中，插入到[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)后，会看当前[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)的节点个数，如果大于8，则会将[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)转为[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)

(c)将key和value封装为Node插入到[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)或[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)后，在判断是否需要扩容，如果需要扩容，就结束put方法。



### JUC

#### 线程池

##### 常用线程池

- **newCachedThreadPool**：可缓存的线程池
  - 在创建新线程的时候如果有可重用的线程，则重用它们，否则创建一个新线程并将其添加到线程池中。
  - 在线程池的 **keepAliveTime** 时间超过默认的 60秒后，该线程会被终止并从缓存中移除，因此在没有线程任务运行的时候，**newCachedThreadPool** 将不会占用系统的线程资源
- **newFixedThreadPool**：固定大小的线程池
  - 如果任务数量大于等于指定线程池中线程的数量，则新提交的任务将在阻塞队列中排队，直到有可用的线程资源。
- **newScheduledThreadPool**：可做任务调度的线程池
  - 可设置在给定延迟时间后执行或者定期执行某个线程任务。
- **newSingleThreadPool** ：单个线程的线程池
  - 在该线程停止或者发生异常的时候，**newSingleThreadPool** 线程池会启动一个新的线程代替该线程继续执行任务
- **newWorkStealingPool**：足够大小的线程池
  - 在内部通过使用多个队列来减少各个线程调度产生的竞争

##### 线程池的7大核心参数：

- 核心线程池的大小【int **corePoolSize**】

- 最大线程数【int **maximumPoolSize**】

- 保持存活时间【long **keepAliveTime**】

- 时间单位【TimeUnit **unit**】

- ###### 阻塞队列【BlockingQueue **workQueue**】

  - `ArrayBlockingQueue`：基于数组结构的有界阻塞队列，按先进先出对元素进行排序。
  - `LinkedBlockingQueue`：基于链表结构的有界/无界阻塞队列，按先进先出对元素进行排序，吞吐量通常高于 ArrayBlockingQueue。
  - `SynchronousQueue`：不是一个真正的队列，而是一种在线程之间移交的机制。要将一个元素放入 SynchronousQueue 中，必须有另一个线程正在等待接受这个元素。如果没有线程等待，并且线程池的当前大小小于最大值，那么线程池将创建一个线程，否则根据拒绝策略，这个任务将被拒绝。使用直接移交将更高效，因为任务会直接移交给执行它的线程，而不是被放在队列中，然后由工作线程从队列中提取任务。只有当线程池是无界的或者可以拒绝任务时，该队列才有实际价值。Executors.newCachedThreadPool使用了该队列。
  - `PriorityBlockingQueue`：具有优先级的无界队列，按优先级对元素进行排序。元素的优先级是通过自然顺序或 Comparator 来定义的。

- 线程工厂【ThreadFactory **threadFactory**】

- ###### 拒绝策略【RejectedExecutionHandler **handle**】

  - **AbortPolicy**：==中止策略==。默认的拒绝策略，直接抛出 RejectedExecutionException。调用者可以捕获这个异常，然后根据需求编写自己的处理代码。
  - **DiscardPolicy**：==抛弃策略==。后面的任务不做任务处理，不执行，也不抛出异常
  - **DiscardOldestPolicy**：==抛弃最老策略==。丢弃最老的任务，就是从队列中取出最老的任务，然后放入新进来的任务执行
  - **CallerRunsPolicy**：==调用者运行策略==。如果线程池未关闭，则调用主线程来帮忙执行新的任务，这也会导致主线程效率变低



##### 线程池的运作流程

任务提交到线程池，会先判断当前线程数量是否小于 corePoolSize，如果小于，则创建线程来执行提交的任务，否则将任务放入到 workQueue 队列，若 workQueue 满了，则判断当前线程数量是否小于 maximumPoolSize，若小于，则创建线程来执行任务，否则就会调用 handler，以表示线程池拒绝接收任务。



##### ThreadPoolExecutor 的五种状态

- **RUNNING** （running）: 线程池创建之后的初始状态，在该状态下可以执行任务
- **SHUTDOWN**（shutdown）: 该状态下线程池不再接收新任务，但是会将工作队列中的任务执行完毕
- **STOP** (stop): 该状态下线程池不再接收新任务，也不会处理工作队列中的剩余任务，并且将会中断所有工作进程
- **TIDYING**（tidying） : 该状态下所有任务都已终止或处理完成，将会执行terminated()钩子方法
- **TERMINATED**（terminated） : 执行完terminated方法之后的状态，此状态已清理完现场。



#### 锁

##### 悲观锁和乐观锁

- 在 Java 语言中 `synchronized` 和 `ReentrantLock`等就是典型的悲观锁，还有一些使用了 synchronized 关键字的容器类如 `HashTable` 等也是悲观锁的应用。

- 乐观锁可以使用`版本号机制`和`CAS算法`实现。在 Java 语言中 `java.util.concurrent.atomic`包下的原子类就是使用CAS 乐观锁实现的。

  > 乐观锁适用于写比较少（冲突比较小）的场景，因为不用上锁、释放锁，省去了锁的开销，从而提升了吞吐量。

  > 如果是写多读少的场景，即冲突比较严重，线程间竞争激励，使用乐观锁就是导致线程不断进行重试，这样可能还降低了性能，这种场景下使用悲观锁就比较合适。

##### 独占锁和共享锁

`独占锁`是指锁一次只能被一个线程所持有。如果一个线程对数据加上排他锁后，那么其他线程不能再对该数据加任何类型的锁。获得独占锁的线程既**能读数据又能修改数据**。

JDK中的`synchronized`和`java.util.concurrent(JUC)`包中`Lock`的实现类就是独占锁。

`共享锁`是指锁可被多个线程所持有。如果一个线程对数据加上共享锁后，那么其他线程只能对数据再加共享锁，不能加独占锁。获得共享锁的线程**只能读数据，不能修改数据**。

在 JDK 中 `ReentrantReadWriteLock` 就是一种共享锁。



##### 互斥锁和读写锁

`互斥锁`是**独占锁的一种常规实现**，是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。

互斥锁一次只能一个线程拥有互斥锁，其他线程只有等待。

`读写锁`是**共享锁的一种具体实现**。读写锁管理一组锁，一个是只读的锁，一个是写锁。

读锁可以在没有写锁的时候被多个线程同时持有，而写锁是独占的。写锁的优先级要高于读锁，一个获得了读锁的线程必须能看到前一个释放的写锁所更新的内容。

读写锁相比于互斥锁并发程度更高，每次只有一个写线程，但是同时可以有多个线程并发读。

在 JDK 中定义了一个读写锁的接口：`ReadWriteLock`



##### 公平锁和非公平锁

`公平锁`是指多个线程按照申请锁的顺序来获取锁，这里类似排队买票，先来的人先买，后来的人在队尾排着，这是公平的。

在 java 中可以通过构造函数初始化公平锁

`非公平锁`是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发环境下，有可能造成优先级翻转，或者饥饿的状态（某个线程一直得不到锁）。

在 java 中 `synchronized` 关键字是非公平锁，``ReentrantLock`默认也是非公平锁。

##### 可重入锁

`可重入锁`又称之为`递归锁`，是指同一个线程在外层方法获取了锁，在进入内层方法会自动获取锁。

对于Java ReentrantLock而言, 他的名字就可以看出是一个可重入锁。对于Synchronized而言，也是一个可重入锁。

敲黑板：可重入锁的一个好处是可一定程度避免死锁。

以 synchronized 为例，看一下下面的代码：

```java
public synchronized void mehtodA() throws Exception{
 // Do some magic tings
 mehtodB();
}
public synchronized void mehtodB() throws Exception{
 // Do some magic tings
}
```

上面的代码中 methodA 调用 methodB，如果一个线程调用methodA 已经获取了锁再去调用 methodB 就不需要再次获取锁了，这就是可重入锁的特性。如果不是可重入锁的话，mehtodB 可能不会被当前线程执行，可能造成死锁。

##### 自旋锁

`自旋锁`是指线程在没有获得锁时不是被直接挂起，而是执行一个忙循环，这个忙循环就是所谓的自旋。

自旋锁的目的是为了减少线程被挂起的几率，因为线程的挂起和唤醒也都是耗资源的操作。

如果锁被另一个线程占用的时间比较长，即使自旋了之后当前线程还是会被挂起，忙循环就会变成浪费系统资源的操作，反而降低了整体性能。因此自旋锁是不适应锁占用时间长的并发情况的。

在 Java 中，`AtomicInteger` 类有自旋的操作，我们看一下代码：

```cpp
public final int getAndAddInt(Object o, long offset, int delta) {
    int v;
    do {
        v = getIntVolatile(o, offset);
    } while (!compareAndSwapInt(o, offset, v, v + delta));
    return v;
}
```

CAS 操作如果失败就会一直循环获取当前 value 值然后重试。

另外自适应自旋锁也需要了解一下。

在JDK1.6又引入了自适应自旋，这个就比较智能了，自旋时间不再固定，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定。如果虚拟机认为这次自旋也很有可能再次成功那就会次序较多的时间，如果自旋很少成功，那以后可能就直接省略掉自旋过程，避免浪费处理器资源。



##### 分段锁

`分段锁` 是一种锁的设计，并不是具体的一种锁。

分段锁设计目的是将锁的粒度进一步细化，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。

在 Java 语言中 ConCurrentHashMap 底层就用了分段锁，使用Segment，就可以进行并发使用了。



#### CAS

CAS是英文单词CompareAndSwap的缩写，中文意思是：==比较并替换==。CAS需要有3个操作数：`内存地址V`，`旧的预期值A`，`即将要更新的目标值B`。

CAS指令执行时，**当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做**。整个比较并替换的操作是一个**原子操作**。

##### CAS的缺点：

1. **循环时间长开销很大。**

   CAS 通常是配合无限循环一起使用的

2. **只能保证一个变量的原子操作。**
   当对一个变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个变量操作时，CAS 目前无法直接保证操作的原子性。但是我们可以通过以下两种办法来解决：1）使用互斥锁来保证原子性；2）将多个变量封装成对象，通过 AtomicReference 来保证原子性。

3. **ABA问题。**



#### AQS

> AQS原理

**AQS**（AbstractQuenedSynchronizer）： 抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制。

**AQS的核心思想**是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
**CLH**（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。
**AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。**

用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。

**注意：AQS是自旋锁：**在等待唤醒的时候，经常会使用自旋（while(!cas())）的方式，不停地尝试获取锁，直到被其他线程获取成功

**实现了AQS的锁有：自旋锁、互斥锁、读锁写锁、条件产量、信号量、栅栏都是AQS的衍生物**

> AQS 定义了两种资源共享方式：

- **Exclusive**：独占，只有一个线程能执行，如ReentrantLock
- **Share**：共享，多个线程可以同时执行，如Semaphore、CountDownLatch、ReadWriteLock，CyclicBarrier



synchronized 和 volatile

1. synchronized 表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程。  

2. volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重[排序]()。  

   **区别**  

-  volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。 
-  volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。 
-  volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。 
-  volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。 
-  volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。

#### **volatile**

**volatile**：java提供的一种**轻量级的同步机制**

- 保证可见性
- 不保证原子性
- 防止指令重排   **内存屏障**



####  **内存溢出**

 **内存溢出**是指应用系统中存在无法回收的内存或使用的内存过多，最终使得程序运行要用到的内存大于虚拟机能提供的最大内存。

  引起内存溢出的**原因**有很多种，常见的有以下几种：
1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据；
2.集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；
3.代码中存在死循环或循环产生过多重复的对象实体；
4.使用的第三方软件中的BUG；
5.启动参数内存值设定的过小；

内存溢出的**解决方案**：
**第一步**，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)

**第二步**，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。

**第三步**，对代码进行走查和分析，找出可能发生内存溢出的位置。

重点排查以下几点：
1.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。
2.检查代码中是否有死循环或递归调用。

3.检查是否有大循环重复产生新对象实体。

4.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。

5.检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。

#### 交替打印AB

```java
/**
 * @author LiuWang
 * @time 2022/07/06 20:16:34
 */
public class PrintAB {

    private static boolean flag = true;
    private static Object lock = new Object();

    public static void main(String[] args) {
        new Thread(()->{
            int i = 10;
            while (i --> 0) {
                synchronized (lock) {
                    while (!flag) {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    System.out.print(Thread.currentThread().getName() + " ");
                    flag = false;
                    lock.notifyAll();
                }
            }
        }, "A").start();
        new Thread(()->{
            int i =10;
            while (i --> 0) {
                synchronized (lock) {
                    while (flag) {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    System.out.print(Thread.currentThread().getName() + " ");
                    flag = true;
                    lock.notifyAll();
                }
            }
        }, "B").start();
    }
}
```



#### 三个线程交替打印1~100

```java
/**
 * @author LiuWang
 * @time 2022/07/07 10:02:14
 */
public class PrintABC100 {

    private static Object lock = new Object();
    private static int flag = 1;
    private static int n = 1;

    public static void main(String[] args) {

        new Thread(()->{
            while (n <= 100) {
                synchronized (lock) {
                    while (flag != 1) {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    System.out.println(Thread.currentThread().getName() + "-->" + n++);
                    flag = 2;
                    lock.notifyAll();
                }
            }
        }, "A").start();
        new Thread(()->{
            while (n <= 100) {
                synchronized (lock) {
                    while (flag != 2) {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    System.out.println(Thread.currentThread().getName() + "-->" + n++);
                    flag = 3;
                    lock.notifyAll();
                }
            }
        }, "B").start();
        new Thread(()->{
            while (n <= 100) {
                synchronized (lock) {
                    while (flag != 3) {
                        try {
                            lock.wait();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        }
                    }
                    System.out.println(Thread.currentThread().getName() + "-->" + n++);
                    flag = 1;
                    lock.notifyAll();
                }
            }
        }, "C").start();
    }
}
```



#### 简单实现死锁

```java
/**
 * @author LiuWang
 * @time 2022/07/07 10:32:54
 */
public class DeadLock {

    private static Object a = new Object();
    private static Object b = new Object();

    public static void main(String[] args) {
        new Thread(()->{
            synchronized (a) {
                System.out.println(Thread.currentThread().getName() + "获得lockA");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (b) {
                    System.out.println(Thread.currentThread().getName() + "尝试获得lockB");
                }
            }
        }, "A").start();
        new Thread(()->{
            synchronized (b) {
                System.out.println(Thread.currentThread().getName() + "获得lockB");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (a) {
                    System.out.println(Thread.currentThread().getName() + "尝试获得lockA");
                }
            }
        }, "B").start();
    }

}
```



### 消息队列

#### RabbitMQ和kafka的区别

**1.应用场景方面**
[RabbitMQ](https://so.csdn.net/so/search?q=RabbitMQ&spm=1001.2101.3001.7020)：用于实时的，对可靠性要求较高的消息传递上。
[kafka](https://so.csdn.net/so/search?q=kafka&spm=1001.2101.3001.7020)：用于处于活跃的流式数据，大数据量的数据处理上。
**2.架构模型方面**
producer，broker，consumer
RabbitMQ：以broker为中心，有消息的确认机制
kafka：以consumer为中心，无消息的确认机制
**3.吞吐量方面**
RabbitMQ：支持消息的可靠的传递，支持事务，不支持批量操作，基于存储的可靠性的要求存储可以采用内存或硬盘，[吞吐量](https://so.csdn.net/so/search?q=吞吐量&spm=1001.2101.3001.7020)小。
kafka：内部采用消息的批量处理，数据的存储和获取是本地磁盘顺序批量操作，消息处理的效率高，吞吐量高。
**4.集群负载均衡方面**
RabbitMQ：本身不支持负载均衡，需要loadbalancer的支持
kafka：采用zookeeper对集群中的broker，consumer进行管理，可以注册topic到zookeeper上，通过zookeeper的协调机制，producer保存对应的topic的broker信息，可以随机或者轮询发送到broker上，producer可以基于语义指定分片，消息发送到broker的某个分片上。





### Redis

#### Redis单线程模型

`Redis基于Reactor模式开发了网络事件处理器,这个处理器就叫做文件事件处理器(file event handler).这个文件事件处理器是单线程的,所以Redis才叫做单线程的模型,`文件事件处理器采用了`IO多路复用机制`同时[监听](https://so.csdn.net/so/search?q=监听&spm=1001.2101.3001.7020)多个socket,根据socket上的事件来选择对应的事件处理器来处理这个事件;

##### redis为什么使用单线程

因为 redis 是完全**基于内存**操作的，通常情况下CPU不会是redis的瓶颈，redis 的瓶颈最有可能是机器内存的大小或者网络带宽。

既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。

最近的 6.0 版本就对核心流程引入了多线程，**主要用于解决 redis 在网络 I/O 上的性能瓶颈**。而对于核心的命令执行阶段，目前还是单线程的。



#### Redis数据一致性

从理论上来说，给缓存==设置过期时间==，是保证最终一致性的解决方案

- **延时双删策略**

  写请求——>删除缓存——>更新数据库——>休眠（1s）——>删除缓存

- **异步更新缓存（基于MySQL binlog的同步机制）**

  1）读取Redis缓存：热数据都在Redis上
  2）写Mysql：增删改都是在Mysql进行操作
  3）更新Redis数据：Mysql的数据操作都记录到binlog，通过消息队列及时更新到Redis上

  - 数据操作主要分为两种：

  ​    1、一种是全量（将所有数据一次性写入Redis）
  ​    2、一种是增量（实时更新）

  ​		这里说的是增量,指的是mysql的update、insert、delate变更数据。

- **删除缓存重试机制**

  写请求更新数据库；缓存因为某些原因，删除失败；把删除失败的key放到消息队列；消费消息队列的消息，获取要删除的key；重试删除缓存操作；



#### Redis大k问题

![image-20220711194855969](面试.assets/image-20220711194855969.png)

什么是大K问题？

- 单个key存储的value很大
- hash、list、set、zset中存储过多的元素

如何避免？

- string类型控制在10KB以内
- hash、list、set、zset元素个数不要超过5000



#### Redis热点Key

**热 key 带来的问题**：请求到的分片过于集中，超过单台 Server 的性能极限。

**解决方案：**

1）服务端缓存：即将热点数据缓存至服务端的内存中；

2）备份热点Key：即将热点Key+随机数，随机分配至 Redis 其它节点中。



#### Redis数据结构

![image-20220711194920226](面试.assets/image-20220711194920226.png)

##### Zset

当前有两种编码：ziplist、skiplist

**ziplist**：使用压缩列表实现，当保存的==元素长度都小于64字节，同时数量小于128==时，使用该编码方式，否则会使用 skiplist。这两个参数可以通过 zset-max-ziplist-entries、zset-max-ziplist-value 来自定义修改。

**skiplist：zset**实现，一个zset同时包含一个==字典（dict）==和一个==跳跃表（zskiplist）==

##### Sorted Set 为什么使用跳跃表，而不是红黑树？

1）跳表的性能和红黑树差不多，都是**O（logN）**的时间复杂度

2）从整体上来看，**跳表算法实现的难度要低于红黑树**。

3）**跳跃表范围查询比平衡树操作简单**。

##### Hash对象扩容

hash 对象在扩容时使用了一种叫“渐进式 rehash”的方式

**扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。**

如果保存在 Redis 中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成 Redis 一段时间内不能进行别的操作。所以 Redis 采用渐进式 rehash。

这样在进行渐进式 rehash 期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。

#### Redis数据过期策略

- **定时删除**

  在设置 key 的过期时间的同时，为该 key 创建一个定时器，让定时器在 key 的过期时间来临时，对 key 进行删除。

- **惰性删除**

  1）在进行get或setnx等操作时，先检查key是否过期；

  2）若过期，删除key，然后执行相应操作；

  3）若没过期，直接执行相应操作。

- **定期删除**
  每隔一段时间执行一次删除（在 redis.conf 配置文件设置，1s 刷新的频率）过期 key 操作。

Redis采用 ==惰性删除 + 定期删除==

#### Redis内存淘汰机制

==volatile（设置过期时间的数据集）==
	1）volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。

​	2）volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。

​	3）volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。

​	4）volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。

==allkeys（所有数据集）==
	5）allkeys-lru：从数据集中挑选最近最少使用的数据淘汰

​	6）allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。

​	7）allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰

==no-enviction==
	8）no-enviction（驱逐）：禁止驱逐数据，这也是默认策略。

**采用 no-enviction 策略可以保证数据不被丢失。**

#### Redis持久化机制

==1）RDB==

**RDB 持久化**是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式。也就是**将内存中数据以快照的方式写入到二进制文件中**，默认的文件名为 dump.rdb。

RDB 支持 **同步（save 命令）、后台异步（bgsave）以及自动配置**三种方式触发。

- **SAVE**：生成 RDB 快照文件，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。
- **BGSAVE：fork** 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。

==2）AOF==

保存 Redis 服务器所执行的所有写操作命令来记录数据库状态，并在服务器启动时，通过重新执行这些命令来还原数据集。

随着时间推移，AOF 持久化文件也会变的越来越大。为了解决此问题，Redis 提供了 `bgrewriteaof` 命令，作用是 fork 出一条新进程将内存中的数据以命令的方式保存到临时文件中，完成对**AOF 文件的重写**。

==3）混合持久化==

如果同时启用了 AOF 和 RDB，Redis 重新启动时，会使用 AOF 文件来重建数据集，因为通常来说， AOF 的数据会更完整。

#### Redis集群

==Redis如何实现高可用？==

- 主从复制
- 哨兵模式
- 集群模式

#### 分布式锁

> 1、场景

修改时，经常需要先将数据读取到内存，在内存中修改后再存回去。在分布式应用中，可能多个进程同时执行上述操作，而读取和修改非原子操作，所以会产生冲突。增加分布式锁，可以解决此类问题。

> 2、基本原理

**同步锁**：在多个线程都能访问到的地方，做一个标记，标识该数据的访问权限。

**分布式锁**：在多个线程都能访问到的地方，做一个标记，标识该数据的访问权限。

> 3、实现方式

1. ==基于数据库实现分布式锁==

2. ==基于Redis实现分布式锁==

   - 加锁

     通常用set命令来实现

   - 解锁

     1）查询当前“锁”是否还是我们持有，因为存在过期时间，所以可能等你想解锁的时候，“锁”已经到期，然后被其他线程获取了，所以我们在解锁前需要先判断自己是否还持有“锁”

     2）如果“锁”还是我们持有，则执行解锁操作，也就是删除该键值对，并返回成功；否则，直接返回失败。

     

     由于当前 Redis 还没有原子命令直接支持这两步操作，所以当前通常是使用 Lua 脚本来执行解锁操作，Redis 会保证脚本里的内容执行是一个原子操作。

     脚本代码如下，逻辑比较简单：

     ```lua
     if redis.call("get",KEYS[1]) == ARGV[1]
     then
         return redis.call("del",KEYS[1])
     else
         return 0
     end
     ```

     

3. ==基于Zookeeper实现分布式锁==

> 4、Redis实现分布式锁的原则

- 安全属性：**独享**。在任一时刻，只有一个客户端持有锁。
- 活性A：**无死锁**。即便持有锁的客户端崩溃或者网络被分裂，锁仍然可以被获取。
- 活性B：**容错**。只要大部分Redis结点都活着，客户端就可以获取和释放锁。

#### 缓存穿透、击穿、雪崩

1. 缓存穿透：==查询数据不存在==

   - **key校验**：如布隆过滤器

     > 使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库。

   - **缓存空值**：当访问缓存和DB都没有查询到值时，可以将空值写进缓存，设置一个较短的过期时间

2. 缓存击穿：==缓存过期，伴随大量对该 key 的请求==

   - **互斥锁**

     > 在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。

   - **热点数据永不过期**：直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。

   - 熔断降级

3. 缓存雪崩：==同一时间大批量的 key 过期==

   - **热点数据不过期**

   - **随机分散过期时间**

     > 可以给缓存的过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。



#### Redis应用场景

1）**String**：缓存、限流、分布式锁、计数器、分布式 Session 等。

2）**Hash**：用户信息、用户主页访问量、组合查询等。

3）**List**：简单队列、关注列表时间轴。

4）**Set**：赞、踩、标签等。

5）**ZSet**：排行榜、好友关系链表。



### MYSQL

#### 三范式

第一范式：每个列都不可以再拆分。

第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。

第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。

#### 慢 SQL 优化

首先要搞明白慢的原因是什么：**是查询条件没有命中索引**？还是 **load 了不需要的数据列**？还是**数据量太大**？所以优化也是针对这三个方向来的。

1）首先用 ==explain==分析语句的执行计划，查看使用索引的情况，是不是查询没走索引，如果可以加索引解决，优先采用加索引解决。

2）分析语句，看看是否存在一些导致索引失效的用法，是否 load 了额外的数据，是否加载了许多结果中并不需要的列，对语句进行分析以及重写。

3）如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行垂直拆分或者水平拆分。

#### explain

explain 字段有：

- id：标识符
- select_type：查询的类型
- table：输出结果集的表
- partitions：匹配的分区
- type：表的连接类型
- possible_keys：查询时，可能使用的索引
- key：实际使用的索引
- key_len：使用的索引字段的长度
- ref：列与索引的比较
- rows：估计要检查的行数
- filtered：按表条件过滤的行百分比
- Extra：附加信息

#### type常见值

按类型排序，从好到坏，常见的有：const > eq_ref > ref > range > index > ALL。

- const：通过主键或唯一键查询，并且结果只有1行（也就是用等号查询）。因为仅有一行，所以优化器的其余部分可以将这一行中的列值视为常量。

- eq_ref：通常出现于两表关联查询时，使用主键或者非空唯一键关联，并且查询条件不是主键或唯一键的等号查询。

- ref：通过普通索引查询，并且使用的等号查询。

- range：索引的范围查找（>=、<、in 等）。

- index：全索引扫描。

- All：全表扫描
  

#### 优化长难的SQL语句

- 将一个大的查询分为多个小的相同查询
- 减少冗余记录的查询
- 一个复杂查询可以考虑拆成多个简单查询
- 分解关联查询，让缓存的效率更高



#### 大表优化

- **1. 限定数据的范围**

  - 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；

- **2. 读/写分离**

  - 经典的数据库拆分方案，主库负责写，从库负责读；

- **3. 垂直分区**

  - 根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。
  - 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。
  - ps：
    - 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。
    - 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

- **4. 水平分区**

  - 保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。

  - 水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。

    

#### 主从复制

主从复制：将主数据库中的DDL（数据定义语言）和DML（数据操纵语言）操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。



#### **MYISAM和INNODB**

InnoDB：支持事务ACID，支持外键，支持崩溃后的安全回复，支持行锁，支持聚簇索引

MyISAM【myaisemu】：不支持事务，不支持外键，不支持崩溃后的安全回复，只支持表级锁，不支持行级锁，不支持聚簇索引

|              | MYISAM | INNODB                    |
| :----------- | ------ | ------------------------- |
| 事务支持     | 不支持 | 支持                      |
| 行级锁       | 不支持 | 支持                      |
| 表级锁       | 支持   | 支持                      |
| 外键约束     | 不支持 | 支持                      |
| 全文索引     | 支持   | 不支持（5.7以后开始支持） |
| 表空间的大小 | 较小   | 较大，约为2倍             |

常规使用操作：

- MYISAM 节约空间，速度较快
- INNODB 安全性高，事务的处理，多表多用户操作



#### B树和B+树

**B+树和B树最大的不同是：**

1. B+树内部有两种结点，一种是索引结点，一种是叶子结点。
2. B+树的索引结点并不会保存记录，只用于索引，所有的数据都保存在B+树的叶子结点中。而B树则是所有结点都会保存数据。
3. B+树的叶子结点都会被连成一条链表。叶子本身按索引值的大小从小到大进行排序。即这条链表是 从小到大的。多了条链表方便范围查找数据。
4. B树的所有索引值是不会重复的，而B+树 非叶子结点的索引值 最终一定会全部出现在 叶子结点中。



**为什么要有B+树：**

要说明这个问题，首先要从B树的好处和不足出发。

> **B树好处：**
>
> B树的每一个结点都包含key(索引值) 和 value(对应数据)，因此方位离根结点近的元素会更快速。（相对于B+树）
>
> **B树的不足：**
>
> 不利于范围查找(区间查找)，如果要找 0~100的索引值，那么B树需要多次从根结点开始逐个查找。
>
> 而B+树由于叶子结点都有链表，且链表是以从小到大的顺序排好序的，因此可以直接通过遍历链表实现范围查找。



#### 索引

- **主键索引**: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。
- **唯一索引**: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。
- **普通索引**: 基本的索引类型，没有唯一性的限制，允许为NULL值。
- **全文索引**：是目前搜索引擎使用的一种关键技术，对文本的内容进行分词、搜索。
- **覆盖索引**：查询列要被所建的索引覆盖，不必读取数据行
- **组合索引**：多列值组成一个索引，用于组合搜索，效率大于索引合并

#### 创建索引的方式

- 第一种方式：在执行CREATE TABLE时创建索引
- 第二种方式：使用ALTER TABLE命令去增加索引
- 第三种方式：使用CREATE INDEX命令创建

#### 主键与索引的区别

- 主键一定会创建一个唯一索引，但是有唯一索引的列不一定是主键；
- 主键不允许为空值，唯一索引列允许空值；
- 一个表只能有一个主键，但是可以有多个唯一索引；
- 主键可以被其他表引用为外键，唯一索引列不可以；
- 主键是一种约束，而唯一索引是一种索引，是表的冗余数据结构，两者有本质区别



#### ACID

**1、原子性（Atomicity）**

指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。

**2、一致性（Consistency）**

事务前后数据的完整性必须保持一致。

**3、隔离性（Isolation）**

事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。

**4、持久性（Durability）**
持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响。**表示事务结束后的数据不随着外界原因导致数据丢失**。

#### 事务隔离级别

**1、read uncommitted（读取未提交）**

最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

**2、read committed（读取已提交）**

允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。

**3、repeatable read（可重复读）**

对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。

**4、serializable（可串行化）**

 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

|     隔离级别     | 脏读 | 不可重复读 | 幻读 |
| :--------------: | :--: | :--------: | :--: |
| READ-UNCOMMITTED |  √   |     √      |  √   |
|  READ-COMMITTED  |  ×   |     √      |  √   |
| REPEATABLE-READ  |  ×   |     ×      |  √   |
|   SERIALIZABLE   |  ×   |     ×      |  ×   |

MySQL InnoDB 存储引擎的默认支持的隔离级别是 `REPEATABLE-READ（可重读）`。

**案例一：**`脏读`：**一个事务读取到另一个事务还未提交的数据**。

事务A，先执行，处于未提交的状态：

```mysql
insert into T values(4, wangwu); 
```

事务B，后执行，也未提交：

```mysql
select * from T; 
```

如果事务B能够读取到(4, wangwu)这条记录，事务A就对事务B产生了影响，这个影响叫做“读脏”，读到了未提交事务操作的记录。

**案例二：**`不可重复读`：**在一个事务中多次读取同一个数据时，结果出现不一致。**

1、事务A，先执行：

```mysql
select * from T where id=1; 
```

结果集为：1, xiaohong

2、事务B，后执行，并且提交：

```mysql
update T set name=hzy where id=1; 
```

commit;

3、事务A，再次执行相同的查询：

```mysql
select * from T where id=1; 
```

结果集为：1, hzy

**这次是已提交事务B对事务A产生的影响，这个影响叫做“不可重复读”，一个事务内相同的查询，得到了不同的结果。**

**案例三：**`幻读`：**在一个事务中使用相同的 SQL 两次读取，第二次读取到了其他事务新插入的行。**

事务A，先执行：

```mysql
select * from T where id>3; 
```

结果集为： NULL

事务B，后执行，并且提交：

```mysql
insert into T values(4, wangwu); 
commit; 
```

事务A，首次查询了id>3的结果为NULL，于是想插入一条为4的记录：

```mysql
insert into T values(4, hzy); 
```

结果集为： Error : duplicate key!

**这次是已提交事务B对事务A产生的影响，这个影响叫做“幻读”。**

#### 事务并发问题

- 数据更新丢失：当并发事务指令交错时，就可能造成 A 对数据的修改被 B 覆盖
- 脏读
- 不可重复读
- 幻读

#### MVCC

- **多版本并发控制**（MVCC=Multi-Version Concurrency Control），是一种用来解决读 - 写冲突的无锁并发控制。也就是为事务分配单向增长的时间戳，为每个修改保存一个版本。版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照（复制了一份数据）。这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。
- **原理**：
  - MVCC 的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3 个隐式字段、undo 日志、Read View 来实现的。
- **可以为数据库解决什么问题**？
  - 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能。同时还可以解决脏读、幻读、不可重复读等事务隔离问题，但不能解决更新丢失问题。

### 计算网络原理

#### OSI七层协议模型

- **物理层**（physical layer）：RJ45、CLOCK、IEEE802.3（中继器、集线器）
- **数据链路层**（data link layer）：PPP、FR、HDLC、VLAN、MAC（网桥、交换机）
- **网络层**（network layer）：==IP、ICMP、ARP、RARP、OSPF==、IPX、RIP、IGRP（交换机）
- **运输层**（transport layer）：==TCP、UDP==、SPX
- **会话层**（session layer）：NFS、SQL、NETBIOS、RPC
- **表示层**（presentation layer）：JPEG、MPEG、ASII
- **应用层**（application layer）：FTP、DNS、Telnet、==SMTP、HTTP、WWW==、NFS

#### TCP/IP四层协议模型

TCP/IP是一个四层的体系结构，他包括（从下到上顺序）：**网络接口层、网际层**（用网际层这个名字是强调这一层是为了解决不同的网络的互联问题）、**运输层、应用层**。不过从实质上讲，TCP/IP只有最上面的三层，因为**最下面的网络接口层并没有具体内容**。

#### 五层协议体系架构

五层体系的协议结构是综合了OSI和TCP/IP的优点的一种协议，包括（从下到上）：**物理层、数据链路层、网络层、运输层、应用层**。（最**底下两层可以称为网络接口层**）
注：五层协议的体系结构只是为介绍网络原理而设计的，实际应用还是TCP/IP四层体系结构。

![image-20220711194635161](面试.assets/image-20220711194635161.png)

==为什么用TCP/IP，而不用OSI？==

**OSI**由于**体系比较复杂**，而且设计先于实现，有**许多设计过于思想化**，不太方便计算机软件实现，因而完全实现OSI参考模型的系统不多，**应用的范围有限**。而TCP/IP协议最早在计算机系统中实现，在Linux、Windows平台中都有稳定的实现，并且提供了简单方便的编程接口（API），可以在其上开发出丰富的应用程序，因此得到了广泛的应用。TCP/IP协议已成为目前互联网事实上的国际标准和工业标准。

#### **简述 tcp 和 udp的区别？**

**1、连接**

- TCP 是==面向连接==的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

**2、服务对象**

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

**3、可靠性**

- TCP 是可靠交付数据的，数据可以==无差错、不丢失、不重复、按需到达==。
- UDP 是尽最大努力交付，不保证可靠交付数据。

**4、拥塞控制、流量控制**

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

**5、首部开销**

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 ==8 个字节==，并且是==固定不变==的，开销较小。

**6、传输方式**

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

**7、分片不同**

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

#### 三次握手，四次挥手

##### 三次握手

==什么是三次握手？==

三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。

==为什么要进行三次握手？==

弄清这个问题，我们需要先弄明白三次握手的目的是什么，能不能只用两次握手来达到同样的目的。

- 第一次握手：客户端发送网络包，服务端收到了。
  这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
- 第二次握手：服务端发包，客户端收到了。
  这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
- 第三次握手：客户端发包，服务端收到了。
  这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

因此，**需要三次握手才能确认双方的接收与发送能力是否正常**。

==进行三次握手：==

- TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了`LISTEN（监听）状态`；
- **第一次握手**：客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 `SYN-SENT（同步已发送状态）状态`。==TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号==。
- **第二次握手**：TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了`SYN-RCVD（同步收到）状态`。==这个报文也不能携带数据，但是同样要消耗一个序号==。
- **第三次握手**：TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入`ESTABLISHED（已建立连接）状态`。==TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号==。
当服务器收到客户端的确认后也进入`ESTABLISHED状态`，此后双方就可以开始通信了。

![img](https://cdn.jsdelivr.net/gh/Aslan-3/imgrepo/img/202207211743145.png)

==为什么TCP客户端最后还要发送一次确认呢？==

> 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。

​    如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。

​    如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认，而是**判断到此次连接为历史连接，那么就会回 RST 报文来断开连接**。由于服务器收不到确认，就知道客户端并没有请求连接。



##### 四次挥手

数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于``ESTABLISHED状态``，然后客户端主动关闭，服务器被动关闭。

==四次挥手的过程如下：==

- 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入``FIN-WAIT-1（终止等待1）状态``。 ==TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。==
- 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了``CLOSE-WAIT（关闭等待）状态``。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
- 客户端收到服务器的确认请求后，此时，客户端就进入``FIN-WAIT-2（终止等待2）状态``，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
- 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了``LAST-ACK（最后确认）状态``，等待客户端的确认。
- 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。==注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入``CLOSED状态``。==
- 服务器只要收到了客户端发出的确认，立即进入``CLOSED状态``。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

![image-20220711200638244](面试.assets/image-20220711200638244.png)

==为什么连接的时候是三次握手，关闭的时候却是四次握手?==

- ①因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。
- ②但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，“你发的FIN报文我收到了”。
- ③只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

==为什么客户端最后还要等待2MSL？==

> MSL（Maximum Segment Lifetime，最长报文段寿命），TCP允许不同的实现可以设置不同的MSL值。

- 第一，``保证客户端发送的最后一个ACK报文能够到达服务器``，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。

- 第二，``防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中``。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

==如果已经建立了连接，但是客户端突然出现故障了怎么办？==

- TCP还设有一个``保活计时器``，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器``每收到一次客户端的请求后都会重新复位这个计时器``，时间通常是设置为2小时，``若两小时还没有收到客户端的任何数据``，服务器就会``发送一个探测报文段``，以后每隔75秒发送一次。``若一连发送10个探测报文仍然没反应``，服务器就认为客户端``出了故障``，接着就``关闭连接``。

#### TCP协议如何保证可靠传输？

##### **1、校验和**

- TCP校验和是一个端到端的校验和，由发送端计算，然后由接收端验证。其**目的是为了发现TCP首部和数据在发送端到接收端之间发生的任何改动**。如果接收方检测到校验和有差错，则TCP段会被**直接丢弃**，重新发送。
- TCP在计算检验和时，会在TCP首部加上一个**12字节的伪首部**。**检验和**总共计算3部分：TCP伪首部，TCP首部、TCP数据。
- 计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。
  - ![image-20220712103748349](面试.assets/image-20220712103748349.png)
  - 发送方：在**发送数据之前计算检验和**，并进行校验和的填充。
  - 接收方：收到数据后，对数据以**同样的方式进行计算**，求出校验和，**与发送方的进行比对**。

##### **2、连接管理** 

- TCP是面向连接的，三次握手和四次挥手都保证了连接的可靠性。
- 保证可靠的连接，是保证可靠性的前提。

##### 3、确认应答和序列号

- 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。
- 会出现数据丢失问题，用重传机制解决。

##### **4、超时重传**

- 在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据。

- ==超时时间如何确定？==

  - RTO：超时重传时间
  - RTT：指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

  **RTO较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；

  **RTO较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

  根据上述的两种情况，我们可以得知，**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

- ==没有收到ACK报文的原因？==

  1. 数据在传输过程中因为网络原因整体丢包，接收方根本没收到。
  2. 接收方接收到了数据，但是发送的ACK报文丢失了。

##### 5、流量控制

- 滑动窗口

  1、引入

  ​	确认--应答--确认--应答 传输方式的缺点：数据包的**往返时间越长，通信的效率就越低**。

  2、窗口大小

  ​	窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

  ​	窗口的实现实际上是操作**系统开辟的一个缓存空间**，发送方主机在等到确认应答返回之前，必须在缓冲	区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

  3、窗口大小的决定因素

  ​	TCP头里面有一个字段叫`Window`，也就是窗口大小

  ​	**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

  ​	所以，**通常窗口的大小是由接收方的窗口大小来决定的**。

- 流量控制

  - **TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

- 窗口关闭

  - **如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**

  ==窗口关闭的危险？==

  - 当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。

  - 这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了**死锁**的现象。

  ==解决==

  - TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**
  - 如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。
    - 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
    - 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

##### **6、拥塞控制**

- 有流量控制为什么还要拥塞控制？

  - 流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么
  - **拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

- 拥塞窗口

  - **拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。
  - 只要网络中没有出现拥塞，`cwnd` 就会增大；
  - 但网络中出现了拥塞，`cwnd` 就减少；

- 怎么知道网络出现拥塞？

  - 其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

- 拥塞控制算法

  - ==慢启动==

    - 意思是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？
    - 规则：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**
    - 慢启动算法，发包的个数是**指数性的增长**。
    - 慢启动门限`ssthresh`（slow start threshold）状态变量，一般来说 `ssthresh` 的大小是 `65535` 字节。
      - 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
      - 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

  - ==拥塞避免==

    - 规则：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

    - 变成了**线性增长**，就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现**丢包现象**，这时就需要对丢失的数据包进行重传。

      当触发了重传机制，也就进入了「拥塞发生算法」。

  - ==拥塞发生==

    - 重传机制

      - 超时重传

        这个时候，ssthresh 和 cwnd 的值会发生变化：

        - `ssthresh` 设为 `cwnd/2`，

        - `cwnd` 重置为 `1` （是**恢复为 cwnd 初始化值**，我这里假定 cwnd 初始化值 1）

        接着，就重新开始慢启动，**慢启动是会突然减少数据流的**。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

        ![image-20220712102606644](面试.assets/image-20220712102606644.png)

      - 快速重传

        - 当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。
        - TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：
          - `cwnd = cwnd/2` ，也就是设置为原来的一半;
          - `ssthresh = cwnd`;
          - 进入快速恢复算法

  - ==快速恢复==

    - 快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。
    - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
    - 重传丢失的数据包；
    - 如果再收到重复的 ACK，那么 cwnd 增加 1；
    - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；
    - ![image-20220712102643505](面试.assets/image-20220712102643505.png)

#### TCP粘包/拆包

> 只有TCP有粘包现象，UDP永远不会粘包，因为TCP是**基于字节流**的协议，而UDP是**基于数据包**的协议

**粘包**：多个数据包被连续存储于连续的缓存中，在对数据包进行读取时由于无法确定发生方的发送边界，而采用某一估测值大小来进行数据读出，若双方的size不一致时就会使指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

**表现形式：**

- 没有粘包和拆包
  
- ![image-20220712112900146](面试.assets/image-20220712112900146.png)
  
- 接收端只收到一个数据包，由于**TCP是不会出现丢包的**，所以这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为**粘包**。这种情况由于接收端不知道这两个数据包的界限，所以对于接收端来说很难处理。
  
- ![image-20220712113008478](面试.assets/image-20220712113008478.png)
  
- 这种情况有两种表现形式，接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了**拆包和粘包**。这两种情况如果不加特殊处理，对于接收端同样是不好处理的。
  - ![image-20220712113027290](面试.assets/image-20220712113027290.png)

    ![image-20220712113036928](面试.assets/image-20220712113036928.png)



**发生原因：**

- 要发送的**数据大于TCP发送缓冲区剩余空间大小**，将会发生拆包。
- 待发送**数据大于MSS（最大报文长度）**，TCP在传输前将进行拆包。
- 要发送的**数据小于TCP发送缓冲区的大小**，TCP将**多次写入缓冲区的数据一次发送**出去，将会发生粘包。
- 接收数据端的应用层**没有及时读取接收缓冲区中的数据**，将发生粘包。

**解决方法：**

- 发送端**给每个数据包添加包首部**，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过**读取包首部的长度字段**，便知道每一个数据包的实际长度了。
- 发送端将每个数据包封装为**固定长度（不够的可以通过补0填充）**，这样接收端每次从接收缓冲区中**读取固定长度的数据**就自然而然的把每个数据包拆分开来。
- 可以在数据包之间**设置边界**，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。



#### HTTP

- 用于客户端与服务端间的通信协议，是一种**基于TCP传输协议**、**简单快速**、**无状态**的**明文通信**协议
- 1.0
  - 短连接：每一次HTTP数据传输都需要新建TCP连接
- 1.1
  - 长连接：通过HTTP Header当中的connection：keep-alive属性，多次HTTP连接可以共享同一个TCP连接，节约带宽
  - 管线化：客户端一次可以发出多个HTTP请求
  - 断点续传：HTTP Header中存在一个Range字段，表示传输数据范围，若传输中意外中断，可以从中断处继续传输，避免从头传输的开销，或是数据量过大可以分段传输
- 2.0
  - 传输多路复用，多个请求可以共用同一个HTTP连接并发的传输
  - 首部压缩：对HTTP首部进行压缩，减小数据包大小
  - 采用二进制格式而不是文本格式（ASCII） # HTTP/1.1 也可以使用二进制传输，例如传输类型为 image/jpg 等文件类型时

#### URI和URL

- URI(Uniform Resource Identifier) 是**统一资源标志符**，可以**唯一标识一个资源**。
- URL(Uniform Resource Location) 是**统一资源定位符**，可以**提供该资源的路径**。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI的作用像身份证号一样，URL的作用更像家庭住址一样。**URL是一种具体的URI**，它不仅唯一标识资源，而且还提供了定位该资源的信息。

#### 一次HTTP请求的全过程

1. 解析请求URL，获得请求的域名——URL：统一资源定位符，协议 + 域名 + 端口 + 资源虚拟路径 + 资源名称 + 参数
2. DNS服务解析域名得到域名对应的IP地址
   - **ps：解析过程中采用 UDP 协议进行通信；DNS 服务器间采用 TCP 协议通信**
   - ①首先查找本地Host文件、浏览器缓存、系统缓存
   - ②从本地DNS服务器进行查询
   - ③访问DNS根服务器，获取org，com等顶级域名服务器列表
   - ④从列表中任选一个顶级域名服务器访问，获取域名对应的权威服务器列表
   - ⑤任选一个域名权威服务器，获取域名对应的具体IP地址
   - ⑥将获取到的IP地址存储到本地DNS服务器中，并开始传输
3. 与访问的服务端口，三次握手和四次挥手后建立传输层TCP协议，进行数据传输
4. 服务器收到请求，并调用对应资源或方法进行处理，并返回视图
5. 浏览器解析视图并显示

#### Session与Cookie

- 无状态指协议对于请求处理没有记忆能力，**即服务端无法确认客户端状态**，可以通过Session与Cookie可以解决HTTP协议无状态的问题
- 区别
  - 1、Cookie存储在客户端中，Session数据存储在服务端中，通过SessionID的方式存储为一个Cookie进行传输
  - 2、Cookie大小限制为4kb，且最多为20个，Session大小数量无限制
  - 3、Cookie可以本地化存储，并设置存活时间，默认-1表示关闭浏览器就清除，大于0表示持久化到磁盘的存储时间，而Session存储SessionID的Cookie的存活时间是默认的-1，即关闭浏览器后就失效
  - 4、Cookie不支持跨域访问，且需要浏览器支持，若浏览器不支持，则Cookie失效，而Session可以通过修改URL的方式存储SessionID



#### HTTPS

- 在HTTP基础上加入了传输层TSL/SSL协议，使用对称、非对称加密和CA证书校验保证数据传输的安全性

- HTTPS加密原理
  - 客户端通过随机密钥对传输数据进行对称加密，再通过公钥对随机密钥进行非对称加密
  - 服务器接收到数据后，通过私钥对随机密钥解密，再通过随机密钥解密数据
  - 在建立TSL连接时，客户端通过接收并验证服务端传来的CA证书，获取公钥，证书可以防止中间人攻击
  
- HTTPS加密流程
  - 建立连接前
    - 1、服务器生成公钥S.pub与私钥S.pri，发送给CA机构，也可以自己生成证书
    - 2、CA机构对公钥S.pub进行签名，生成CA证书，返回给服务器
  - 建立连接时
    - 1、建立 TLS 连接时，客户端与服务端确认加密算法，服务端将CA证书返回给客户端
    - 2、客户端认证证书的合法性，包括证书机构，有效期等，并解析获取到公钥S.pub
    - 3、客户端随机生成加密密钥，并将随机密钥使用S.pub公钥非对称加密，传输给服务器
    - 4、服务器使用私钥S.pri对随机密钥进行解密
  - 建立连接后，客户端与服务端使用随机密钥进行数据的加密与解密
  
- 数字证书

  - 1、证书颁发机构名称
    - 防止伪造
  - 2、证书本身的数字签名
    - 防止伪造
  - 3、数字签名（摘要）中使用的 Hash 算法
    - 防止被篡改
  - 4、公钥

  - 验证流程
    - 1、验证颁发机构是否有效
    - 2、若颁发机构有效，通过内置的根证书与 CA 公钥对证书数字签名进行解密
    - 3、解密得到证书的数字摘要 A，再使用证书提供的 Hash 算法对实际证书内容计算得到摘要 B，若 A != B，则证书内容被篡改
    - 4、验证证书的时效性



#### HTTP和HTTPS区别

- 端口不同：HTTP和HTTPS 的连接方式不同没用的端口也不一样，**HTTP是80， HTTPS 用的是443（问过！！！）**
- 消耗资源：和HTTP相比，HTTPS通信会因为加解密的处理消耗更多的CPU和内存资源。
- 开销： HTTPS 通信需要证书，这类证书通常需要向认证机构申请或者付费购买。

#### HTTP状态响应码

- 200：成功，Web 服务器成功处理了客户端的请求。
- 301：永久重定向，当客户端请求一个网址的时候，Web 服务器会将当前请求重定向到另一个网址，搜索引擎会抓取重定向后网页的内容并且将旧的网址替换为重定向后的网址。
- 302：临时重定向，搜索引擎会抓取重定向后网页的内容而保留旧的网址，因为搜索引擎认为重定向后的网址是暂时的。
- 400：客户端请求错误，多为参数不合法导致 Web 服务器验参失败。
- 404：未找到，Web 服务器找不到资源。
- 500：Web 服务器错误，服务器处理客户端请求的时候发生错误。
- 503：服务不可用，服务器停机。
- 504：网关超时。



### 操作系统

#### 进程和线程

**进程**：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。**（进程是资源分配的最小单位）**

**线程：**同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。**（线程是cpu调度的最小单位）**



线程和进程一样分为**五个阶段**：创建、就绪、运行、阻塞、终止。



> **线程共享**

- 进程 **代码段**
- 进程 **数据段**
- 进程打开的**文件描述符**
- **信号**的处理器
- 进程的当前**目录**
- **进程用户id**与**进程组id**
- **堆**  

> **线程独有**

- 线程id
- 寄存器组的值
- 线程的栈     `堆栈是保证线程独立运行所必须的`
- 错误返回代码
- 线程的信号屏蔽码



#### 进程间的通信

**1、共享存储**

两个进程对共享空间的访问必须是互斥的

> 两种方式

- **基于数据结构的共享**：比如共享空间里只能放一个长度为10的数组。这种共享方式速度慢、限制多，是一种低级通信方式。

- **基于存储区的共享**：在内存中画一块共享存储区，数据的形式、存放的位置都由进程控制，而不是操作系统。相比之下，这种共享方式更快，是一种高级通信方式。

**2、管道通信**

- 管道只能采用半双工通道，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道。
- 各进程要互斥的访问管道。
- 数据以字符流的形式写入管道，当管道写满时，写进程的write（）系统调用将被阻塞，等待读进程将数据取走。当读进程将数据全部取走后，管道变空，此时读进程的read（）系统调用将被阻塞。
- 如果没写满，就不允许读。如果没读空，就不允许写。
- 数据一旦被读出，就从管道中被抛弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情况。

**3、消息传递**

进程间的数据交换以格式化的消息（Message）为单位。进程通过操作系统提供的“发送消息/接收消息”两个原语进行数据交换。

- **直接通信**方式就是消息直接挂到接受进程的消息缓冲队列上。

- **间接通信**方式就是消息要先发送到中间实体（信箱）中，因此也称“信箱通信方式”，比如，计网中的电子邮件系统

**4、信号量**

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 

**5、消息队列**

 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 

**6、套接字**

套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。



#### 并发和并行

**并发**：一个处理器同时处理多个任务，**逻辑上的同时发生**。==交替执行==

**并行**：多个处理器或者是多核的处理器同时处理多个不同的任务，**物理上的同时发生**。==同时执行==



#### 死锁

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象

> 产生死锁的4个必要条件

- **互斥条件**：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
- **请求和保持条件**：当进程因请求资源而阻塞时，对已获得的资源保持不放。
- **不剥夺条件**：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
- **环路等待条件**：在发生死锁时，必然存在一个进程--资源的环形链。

>预防死锁（互斥条件不能破坏）

- **资源一次性分配**：一次性分配所有资源，这样就不会再有请求了：`（破坏请求和保持条件）`
- 只要有一个资源得不到分配，也不给这个进程分配其他的资源：`（破坏请求和保持条件）`
- **可剥夺资源**：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源`（破坏不可剥夺条件）`
- **资源有序分配法**：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反`（破坏环路等待条件）`

#### BIO NIO AIO

**BIO：同步阻塞式IO，**服务器实现模式为**一个连接一个线程**，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 
**NIO：同步非阻塞式IO**，服务器实现模式为**一个请求一个线程**，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。 
**AIO：异步非阻塞式IO，**服务器实现模式为**一个有效请求一个线程**，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 

### Spring

#### **IOC**

借助Spring实现具有依赖关系的对象之间的解耦。

对象A运行需要对象B，由主动创建变为IOC容器注入，这便是控制反转。

获得依赖对象的过程被反转了，获取依赖对象的过程由自身创建变为由IOC容器注入，这便是依赖注入。

**三种注入方式：**

- 构造器注入
- setter方法注入
- 注解注入
- 接口方式注入（不推荐）



### Spring MVC

#### SpringMVC执行流程

![image-20220711194951638](面试.assets/image-20220711194951638.png)

1、 用户发送请求至前端控制器`DispatcherServlet`。
2、 `DispatcherServlet`收到请求调用`HandlerMapping`处理器映射器。
3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给`DispatcherServlet`。
4、 `DispatcherServlet`调用`HandlerAdapter`处理器适配器。
5、 `HandlerAdapter`经过适配调用具体的处理器(Controller，也叫后端控制器)。
6、 `Controller`执行完成返回`ModelAndView`。
7、 `HandlerAdapter`将`controller`执行结果`ModelAndView`返回给`DispatcherServlet`。
8、 `DispatcherServlet`将`ModelAndView`传给`ViewReslover`视图解析器。
9、 `ViewReslover`解析后返回具体`View`。
10、`DispatcherServlet`根据`View`进行渲染视图（即将模型数据填充至视图中）
11、 `DispatcherServlet`响应用户





### 幂等性

**幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。**举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即[回滚](https://so.csdn.net/so/search?q=回滚&spm=1001.2101.3001.7020)，但是再响应客户端的时候也有可能出现网络中断或者异常等等。

在增删改查4个操作中，**尤为注意就是增加或者修改**，查询对于结果是不会有改变的，删除只会进行一次，用户多次点击产生的结果一样，修改在大多场景下结果一样，增加在重复提交的场景下会出现。

那么如何设计接口才能做到[幂等](https://so.csdn.net/so/search?q=幂等&spm=1001.2101.3001.7020)呢？

**方法一**：单次支付请求，也就是直接支付了，不需要额外的数据库操作了，这个时候发起异步请求创建一个唯一的ticketId，就是门票，这张门票只能使用一次就作废，具体步骤如下：

1、异步请求获取门票

2、调用支付，传入门票

3、根据门票ID查询此次操作是否存在，如果存在则表示该操作已经执行过，直接返回结果；如果不存在，支付扣款，保存结果

4、返回结果到客户端

如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的.

**方法二**：分布式环境下各个服务相互调用

这边就要举例我们的系统了，我们支付的时候先要扣款，然后更新订单，这个地方就涉及到了订单服务以及支付服务了。用户调用支付，扣款成功后，更新对应订单状态，然后再保存流水。而在这个地方就没必要使用门票ticketId了，因为会比较闲的麻烦（支付状态：未支付，已支付）

步骤：

1、查询订单支付状态

2、如果已经支付，直接返回结果

3、如果未支付，则支付扣款并且保存流水

 4、返回支付结果

如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的

对于做过支付的朋友，幂等也可以称之为冲正，保证客户端与服务端的交易一致性，避免多次扣款。

以下为接口文档对于幂等的描述，通过请求id号来判断是否为同一个请求。

### 自我介绍

面试官 您好，我叫刘汪，就读于中北大学的软件学院，所学专业是软件工程，目前大三，主修课程有数据结构与计算机网络原理，操作系统，数据库，网站建设与网页设计，javaEE 等，在校期间自学的时候做过一些Java相关的项目，一个是秒杀项目，主要负责秒杀功能的开发和秒杀接口的优化，通过优化使秒杀接口的QPS从200多提升到了1300多；还有一个论坛项目，主要实现了发帖，回帖，点赞，关注，通知等功能，从这些项目中学会了一些java的开发技能，积累了一些的经验。所以想找一份java开发相关的实习工作，从中进一步提高自己的技术能力，以上就是我的个人介绍，谢谢。

![image-20220316212835350](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20220316212835350.png)

### 菜鸟简历面

1、**自我介绍**

2、做过的项目

3、实现的功能

4、中间件做了哪些功能

5、redis怎么优化的网站性能

6、redis的应用场景

7、kafka做了啥

8、**kafka支持事务消息吗，讲一下kafka 的事务消息**

9、**对事务的概念了解吗**（我讲的acid和隔离级别）

10、**幻读的原因**

- 事务A按照一定条件进行数据读取，期间事务B插入了相同搜索条件的新数据，事务A再次按照原先条件进行读取操作修改时，发现了事务B新插入的数据称之为幻读。

11、**数据库里面有读写锁吗**

- 读锁：是一种共享锁，一个事务持有读锁时，不会阻塞其它的读锁，其他事务都可以对该数据进行读取；
- 写锁：是一种排他锁，一个锁持有写锁会阻塞其他的写锁和读锁，从而保证了一个只有一个事务进行写操作，并且防止其他事务读取正在写入资源，避免了脏读；

12、**幂等性**

13、做过并发的编程吗

14、**并发会遇到什么问题**

15、线程池用过吗，怎么用的（我说的7个参数)

16、乐观锁和悲观锁了解吗

17、**分布式里的悲观锁实现，乐观锁的实现**（我说的cas）

- 在 Java 语言中 `synchronized` 和 `ReentrantLock`等就是典型的悲观锁，还有一些使用了 synchronized 关键字的容器类如 `HashTable` 等也是悲观锁的应用。

- 乐观锁可以使用`版本号机制`和`CAS算法`实现。在 Java 语言中 `java.util.concurrent.atomic`包下的原子类就是使用CAS 乐观锁实现的。

  > 乐观锁适用于写比较少（冲突比较小）的场景，因为不用上锁、释放锁，省去了锁的开销，从而提升了吞吐量。

  > 如果是写多读少的场景，即冲突比较严重，线程间竞争激励，使用乐观锁就是导致线程不断进行重试，这样可能还降低了性能，这种场景下使用悲观锁就比较合适。

18、职业规划

19、有什么想问的吗

### 排序复杂度

![img](https://img-blog.csdnimg.cn/img_convert/6611f12fde5c92d2aa299a172794b2e0.png)

### servlet的生命周期

- Servlet 通过调用 **init ()** 方法进行初始化。
- Servlet 调用 **service()** 方法来处理客户端的请求。

- Servlet 通过调用 **destroy()** 方法终止（结束）。

答出 init 和 destroy方法只调用一次的可以适当加分

**1、加载和实例化**

servlet 容器负责加载和实例化servlet 当容器启动或在容器中检测到需要这个servlet来响应一个请求 时。创建servlet实例。容器通过java 的反射API来创建servlet实例.所以servlet中不应该提供带参数的构造函数。

**2、初始化**

在servlet实例化后，容器必须调用 init() 方法来初始化这个对象。初始化的目的是为了让servlet对象在处理客户请求之前完成一些初始工作。对于每一个servlet实例，init() 方法只会调用一次。

**3、请求处理**

servlet 容器调用service()方法对请求处理。servlet 实例通过ServletRequest对象获得客户端的相关信息和请求信息。在对请求处理后调用ServletResponse对象设置响应信息。

**4、服务终止**

当容器检测到一个servlet实例应该从服务器中移除时，容器调用实例的destory方法。让实例释放它所占用的资源。如果在次发请求就会 创建一个新的servlet 实例。

   在整个servlet 的生命周期中，创建servlet实例，调用实例的init()和destory()方法都只执行一次，当初始话完成后，servlet容器将该实例保存在内存中，通过servlce() 方法为接受请求服务。



### 树

#### 二叉树

- ==满二叉树==

  除最后一层无任何子节点外，每一层上的所有节点都有两个子节点，最后一层都是叶子节点。

- ==完全二叉树==

  若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是完全二叉树。

  - 完全二叉树只允许最后一层有空缺结点且空缺在右边，即叶子节点只能在层次最大的两层上出现；
  - 而且对任意一个节点，如果其右子树的深度为j，则其左子树的深度必为j或j+1。 即度为1的点只有1个或0个；
  - 有n个节点的完全二叉树，其深度为：log2的n+1次方；
  - 满二叉树一定是完全二叉树，完全二叉树不一定是满二叉树。

- ==二叉搜索树（BST）==

  左子树的键值小于根的键值，右子树的键值大于根的键值。

- ==平衡二叉树（AVL）==

  平衡二叉树（AVL树）在符合二叉查找树的条件下，还满足任何节点的两个子树的高度最大差为1。

#### 红黑树（RBT）

红黑树就是每个节点都带有颜色属性，颜色或者是红色或者是黑色的平衡二叉查找树。

==特性==

- 节点是红色或黑色
- 根节点一定是黑色
- 每个叶节点都是黑色的空节点(NIL节点)
- 每个红节点的两个子节点都是黑色的(从每个叶子到跟的所有路径上不能有两个连续的红节点)(即对于层来说除了NIL节点，红黑节点是交替的，第一层是黑节点那么其下一层肯定都是红节点，反之一样)
- 从任一节点到其每个叶子节点的所有路径都包含相同数目的黑色节点。

==左旋==

一般情况下，如果左子树深度过深，那么便需要进行左旋操作以保证左右子树深度差变小	

![image-20220704211045257](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20220704211045257.png)

==右旋==

与左旋相反

![image-20220704211529873](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20220704211529873.png)

==总结==

（1） 当出现新的节点时默认为红色插入，如果其父节点为红色，则对其递归向上换色，如果根节点由此变为红色，则对根节点进行左旋（右侧过深）或右旋（左侧过深），之后从根节点向下修改颜色.

（2）从根节点检查红色节点是否符合路径上的黑色节点数量一致，如果不一致，对该节点进行左旋（右侧黑色节点数量更多）或右旋（左侧黑色节点数量更多），并变换颜色，重复2操作直到符合红黑树规则。


#### B-树（平衡多路查找树）

B-Tree是为磁盘等外存储设备设计的一种平衡查找树。

系统从磁盘读取数据到内存时是以`磁盘块（block）`为基本单位的，位于同一个磁盘块中的数据会被`一次性读取`出来，而不是需要什么取什么。

InnoDB存储引擎中有页（Page）的概念，`页是其磁盘管理的最小单位`。InnoDB存储引擎中默认每个页的大小为`16KB`，可通过参数innodb_page_size将页的大小设置为4K、8K、16K

==B-Tree结构的数据可以让系统高效的找到数据所在的磁盘块==

![image-20220704212955279](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20220704212955279.png)

**模拟查找关键字29的过程：**
（1）根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】
（2）比较关键字29在区间（17,35），找到磁盘块1的指针P2。
（3）根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】
（4）比较关键字29在区间（26,30），找到磁盘块3的指针P2。
（5）根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】
（6）在磁盘块8中的关键字列表中找到关键字29。

分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于平衡二叉树缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。


#### B+树

从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。

**B+Tree相对于B-Tree有几点不同：**
（1）非叶子节点只存储键值信息。
（2）所有叶子节点之间都有一个链指针。
（3）数据记录都存放在叶子节点中。

![image-20220704223305327](C:\Users\86178\AppData\Roaming\Typora\typora-user-images\image-20220704223305327.png)





### Linux kill 和 kill -9 的区别

kill命令格式：==kill -Signal pid==

执行kill命令，系统会发送一个SIGTERM信号给对应的程序。当程序接收到该signal信号后，将会发生以下事情：

- 程序立刻停止

- 当程序释放相应资源后再停止

- 程序可能仍然继续运行

大部分程序接收到SIGTERM信号后，会先释放自己的资源，然后再停止。

**kill 和 kill -9 是常用的命令，都可以用来杀死进程。**

默认参数下，kill 发送SIGTERM（15）信号给进程，告诉进程，你需要被关闭，请**自行停止运行并退出**。
kill -9 发送SIGKILL信号给进程，告诉进程，你被终结了，请立刻退出。
TERM(或数字9）表示“无条件终止”；
因此 **kill - 9 表示强制杀死该进程**；与SIGTERM相比，这个信号不能被捕获或忽略，同时接收这个信号的进程在收到这个信号时不能执行任何清理。



### 设计一个LRU Cache

实现本题的两种操作，需要用到一个**哈希表**和一个**双向链表**。在面试中，面试官一般会期望读者能够自己实现一个简单的双向链表，而不是使用语言自带的、封装好的数据结构。在 Java 语言中，有类似的数据结构 `LinkedHashMap`。这些做法都不会符合面试官的要求，因此下面只给出使用封装好的数据结构实现的代码，而不多做任何阐述。

```java
class LRUCache extends LinkedHashMap<Integer, Integer>{
    private int capacity;
    
    public LRUCache(int capacity) {
        super(capacity, 0.75F, true);
        this.capacity = capacity;
    }

    public int get(int key) {
        return super.getOrDefault(key, -1);
    }

    public void put(int key, int value) {
        super.put(key, value);
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
        return size() > capacity; 
    }
}
```

#### 哈希表+双向链表

- 双向链表按照被使用的顺序存储了这些键值对，**靠近头部的键值对是最近使用的**，而靠近尾部的键值对是最久未使用的。
- 哈希表即为普通的哈希映射（HashMap），通过缓存数据的键映射到其在双向链表中的位置。

这样以来，我们首先使用哈希表进行定位，找出缓存项在双向链表中的位置，随后将其移动到双向链表的头部，即可在 O(1)O(1) 的时间内完成 get 或者 put 操作。具体的方法如下：

- 对于 `get` 操作，首先判断 key 是否存在：

  - 如果 key 不存在，则返回 -1−1；

  - 如果 key 存在，则 key 对应的节点是最近被使用的节点。通过哈希表定位到该节点在双向链表中的位置，并将其移动到双向链表的头部，最后返回该节点的值。

- 对于 `put` 操作，首先判断 key 是否存在：

  - 如果 key 不存在，使用 key 和 value 创建一个新的节点，在双向链表的头部添加该节点，并将 key 和该节点添加进哈希表中。然后判断双向链表的节点数是否超出容量，如果超出容量，则删除双向链表的尾部节点，并删除哈希表中对应的项；

  - 如果 key 存在，则与 get 操作类似，先通过哈希表定位，再将对应的节点的值更新为 value，并将该节点移到双向链表的头部。

上述各项操作中，访问哈希表的**时间复杂度为 O(1)**，在双向链表的头部添加节点、在双向链表的尾部删除节点的复杂度也为 O(1)。而将一个节点移到双向链表的头部，可以分成「删除该节点」和「在双向链表的头部添加节点」两步操作，都可以在 O(1) 时间内完成。

**ps：**在双向链表的实现中，使用一个**伪头部（dummy head）**和**伪尾部（dummy tail）**标记界限，这样在添加节点和删除节点的时候就不需要检查相邻的节点是否存在。

```java
public class LRUCache {
    class DLinkedNode {
        int key;
        int value;
        DLinkedNode prev;
        DLinkedNode next;
        public DLinkedNode() {}
        public DLinkedNode(int _key, int _value) {key = _key; value = _value;}
    }

    private Map<Integer, DLinkedNode> cache = new HashMap<Integer, DLinkedNode>();
    private int size;
    private int capacity;
    private DLinkedNode head, tail;

    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        // 使用伪头部和伪尾部节点
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head.next = tail;
        tail.prev = head;
    }

    public int get(int key) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            return -1;
        }
        // 如果 key 存在，先通过哈希表定位，再移到头部
        moveToHead(node);
        return node.value;
    }

    public void put(int key, int value) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            // 如果 key 不存在，创建一个新的节点
            DLinkedNode newNode = new DLinkedNode(key, value);
            // 添加进哈希表
            cache.put(key, newNode);
            // 添加至双向链表的头部
            addToHead(newNode);
            ++size;
            if (size > capacity) {
                // 如果超出容量，删除双向链表的尾部节点
                DLinkedNode tail = removeTail();
                // 删除哈希表中对应的项
                cache.remove(tail.key);
                --size;
            }
        }
        else {
            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node.value = value;
            moveToHead(node);
        }
    }

    private void addToHead(DLinkedNode node) {
        node.prev = head;
        node.next = head.next;
        head.next.prev = node;
        head.next = node;
    }

    private void removeNode(DLinkedNode node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }

    private void moveToHead(DLinkedNode node) {
        removeNode(node);
        addToHead(node);
    }

    private DLinkedNode removeTail() {
        DLinkedNode res = tail.prev;
        removeNode(res);
        return res;
    }
}
```











































































































